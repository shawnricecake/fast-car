import warnings

from dataclasses import dataclass, field


@dataclass
class Dataset:
    dataset_name: str
    dataset_type: str = field(default="torch")
    data_path: str = field(default=None, metadata={"help": "Path to the training data."})
    meta_path: str = field(default=None, metadata={"help": "Path to the meta data for webdataset."})
    image_path: str = field(default=None, metadata={"help": "Path to the training image data."})
    description: str = field(
        default=None,
        metadata={
            "help": "Detailed desciption of where the data is from, how it is labelled, intended use case and the size of the dataset."
        },
    )
    test_script: str = (None,)
    maintainer: str = (None,)


DATASETS = {}


def add_dataset(dataset):
    if dataset.dataset_name in DATASETS:
        warnings.warn(f"{dataset.dataset_name} already existed in DATASETS. Make sure the name is unique.")
    assert "+" not in dataset.dataset_name, "Dataset name cannot include symbol '+'."

    DATASETS.update({dataset.dataset_name: dataset})


def register_datasets_mixtures():
    internal_generation = Dataset(
        dataset_name="internal_generation",
        dataset_type="internal-generation",
        data_path="",
        meta_path="",
    )
    add_dataset(internal_generation)


    # Please download data from https://github.com/NJU-PCALab/OpenVid-1M to prepare openvid_generation.
    openvid_generation = Dataset(
        dataset_name="openvid_generation",
        dataset_type="openvid-generation",
        data_path="",
    )
    add_dataset(openvid_generation)


    # Please download data from https://sharegpt4v.github.io/ to prepare sharegpt4v.
    sharegpt4v_pretrain = Dataset(
        dataset_name="sharegpt4v_pretrain",
        dataset_type="torch",
        data_path="",
        image_path="",
        description="Original data source: https://sharegpt4v.github.io/ ~1M long Image - Text pair generated by ShareGPT4V captioner.",
    )
    add_dataset(sharegpt4v_pretrain)


    sharegpt4v_sft = Dataset(
        dataset_name="sharegpt4v_sft",
        dataset_type="torch",
        data_path="",
        image_path="",
        description="Original data source: https://sharegpt4v.github.io/ 655K llava_1_5_sft data relablled w/ ShareGPT4V captioner.",
    )
    add_dataset(sharegpt4v_sft)
    

    # Please refer to https://github.com/NVlabs/VILA/tree/main/data_prepare to prepare the following datasets.
    mmc4core = Dataset(
        dataset_name="mmc4core",
        dataset_type="mmc4",
        data_path="",
    )
    add_dataset(mmc4core)
    

    vflan = Dataset(
        dataset_name="vflan",
        dataset_type="vflan",
        data_path="",
    )
    add_dataset(vflan)


    shot2story_shotonly = Dataset(
        dataset_name="shot2story_shotonly",
        dataset_type="torch",
        data_path="",
        image_path="",
    )
    add_dataset(shot2story_shotonly)


    video_chatgpt = Dataset(
        dataset_name="video_chatgpt",
        dataset_type="torch",
        data_path="",
        image_path="",
    )
    add_dataset(video_chatgpt)


    youcook2 = Dataset(
        dataset_name="youcook2",
        dataset_type="torch",
        data_path="",
        image_path="",
    )
    add_dataset(youcook2)


    vatex = Dataset(
        dataset_name="vatex",
        dataset_type="torch",
        data_path="",
        image_path="",
    )
    add_dataset(vatex)


    sharegpt_video = Dataset(
        dataset_name="sharegpt_video",
        dataset_type="torch",
        data_path="",
        image_path="",
    )
    add_dataset(sharegpt_video)


    scienceqa = Dataset(
        dataset_name="scienceqa",
        dataset_type="torch",
        data_path="",
        image_path="",
    )
    add_dataset(scienceqa)


    wit_subset = Dataset(
        dataset_name="wit_subset",
        dataset_type="torch",
        data_path="",
        image_path=""
    )
    add_dataset(wit_subset)


    sherlock = Dataset(
        dataset_name="sherlock",
        dataset_type="torch",
        data_path="",
        image_path="",
    )
    add_dataset(sherlock)